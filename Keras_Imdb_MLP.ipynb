{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rm_tags(text):\n",
    "    re_tag = re.compile(r'<[^>]+>')\n",
    "    return re_tag.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_files(filetype):\n",
    "    path = \"data/aclImdb/\"\n",
    "    file_list = []\n",
    "    positive_path = path + filetype + \"/pos/\"\n",
    "    for f in os.listdir(positive_path):\n",
    "        file_list += [positive_path + f]\n",
    "    negative_path = path + filetype + \"/neg/\"\n",
    "    for f in os.listdir(negative_path):\n",
    "        file_list += [negative_path + f]\n",
    "    print('read', filetype, 'files:', len(file_list))\n",
    "    all_labels = ([1] * 12500 + [0] * 12500)\n",
    "    all_texts = []\n",
    "    for fi in file_list:\n",
    "        with open(fi, encoding='utf-8') as file_input:\n",
    "            all_texts += [rm_tags(\" \".join(file_input.readlines()))]\n",
    "    return all_labels, all_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read train files: 25000\n"
     ]
    }
   ],
   "source": [
    "y_train, train_text = read_files(\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read test files: 25000\n"
     ]
    }
   ],
   "source": [
    "y_test, test_text = read_files(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer(num_words=2000)\n",
    "token.fit_on_texts(train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_seq = token.texts_to_sequences(train_text)\n",
    "x_test_seq = token.texts_to_sequences(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = sequence.pad_sequences(x_train_seq, maxlen=100)\n",
    "x_test = sequence.pad_sequences(x_test_seq, maxlen=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Embedding(output_dim=32, input_dim=2000, input_length=100))\n",
    "model.add(Dropout(0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=256, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dropout(0.35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 20000 samples, validate on 5000 samples\n",
      "Epoch 1/10\n",
      " - 2s - loss: 0.4704 - acc: 0.7631 - val_loss: 0.3899 - val_acc: 0.8278\n",
      "Epoch 2/10\n",
      " - 1s - loss: 0.2615 - acc: 0.8922 - val_loss: 0.5926 - val_acc: 0.7412\n",
      "Epoch 3/10\n",
      " - 1s - loss: 0.1572 - acc: 0.9420 - val_loss: 0.7424 - val_acc: 0.7334\n",
      "Epoch 4/10\n",
      " - 1s - loss: 0.0785 - acc: 0.9741 - val_loss: 0.7487 - val_acc: 0.7764\n",
      "Epoch 5/10\n",
      " - 1s - loss: 0.0457 - acc: 0.9831 - val_loss: 0.8554 - val_acc: 0.7864\n",
      "Epoch 6/10\n",
      " - 1s - loss: 0.0346 - acc: 0.9883 - val_loss: 1.0565 - val_acc: 0.7684\n",
      "Epoch 7/10\n",
      " - 1s - loss: 0.0310 - acc: 0.9896 - val_loss: 1.1964 - val_acc: 0.7548\n",
      "Epoch 8/10\n",
      " - 1s - loss: 0.0246 - acc: 0.9914 - val_loss: 1.7215 - val_acc: 0.6958\n",
      "Epoch 9/10\n",
      " - 1s - loss: 0.0229 - acc: 0.9916 - val_loss: 1.3167 - val_acc: 0.7582\n",
      "Epoch 10/10\n",
      " - 1s - loss: 0.0267 - acc: 0.9900 - val_loss: 1.4399 - val_acc: 0.7394\n"
     ]
    }
   ],
   "source": [
    "tarin_history = model.fit(x_train, y_train, batch_size=100, epochs=10, verbose=2, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 44us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.81368"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "scores[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 0, 1, 0], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_classes = predict.reshape(-1)\n",
    "predict_classes[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SetimentDict = {1:'正面的', 0:'负面的'}\n",
    "def display_test_Setiment(i):\n",
    "    print(test_text[i])\n",
    "    print('label真实值:', SetimentDict[y_test[i]], '预测结果:', SetimentDict[predict_classes[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I have always loved the ironic symbolism and brilliant cinematography of Coppola's masterpiece. I was lucky enough to meet Martin Sheen outside the Santa Monica Civic Auditorium one night in 1981, as he waited for Charlie and Emilio to leave a concert. He was very humble about the praise I shared with him for this work of art, especially his portrayal of the young Captain. This is, without a doubt, a must see, a complete 10 and an important part of American Film History. \"Charlie Don't Surf\". Robert Duvall's famous line (the other one) does not need repeating as it has become an oft repeated anthem and his Pattonesque character will long be remembered as a classic American war hawk in the John Wayne tradition. It is a surprise to see how young Laurence Fishburne looks.\n",
      "label真实值: 正面的 预测结果: 正面的\n"
     ]
    }
   ],
   "source": [
    "display_test_Setiment(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am not quite sure I agree with the director of this version of The Scarlet Pimpernel. I imagined Sir Percy Blakeney a very calm, seemingly lazy aristocrat. This particular Sir Percy Blakeney appears to be teeming with overwhelming energy and volatility. I did not appreciate the Houdini, James Bond, Mission Impossible style escapes that Sir Percy engineered either. In the previous versions, wit was the tool for escape, not technology. Neither were the characters of Marguerite and Chauvelin adequately portrayed. There seemed to be little energy or chemistry in the interaction between the characters.I do not wish to assign any blame, for perhaps the reason for my dislike of this movie might simply be a matter of difference in interpretation. Had the director's interpretation coincided with mine, perhaps I might not have been irritated by what seemed to me bad character portrayals.I much preferred the version from 1982. Anthony Andrews was quite efficient as the imperturbable, calm fop. So were Jane Seymour and Ian McKellen. In my opinion, the style of this period piece seems to have been lost with this latest adaption. I recommend sticking with the previous versions, either the one from 1934 or the one from 1982.\n",
      "label真实值: 负面的 预测结果: 负面的\n"
     ]
    }
   ],
   "source": [
    "display_test_Setiment(12503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
